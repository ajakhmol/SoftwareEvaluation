{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO87ELMwMGa7GpKSoyGX32i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajakhmol/SoftwareEvaluation/blob/main/EvaluationRecommendationEngine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "IS03udjkJ-vb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: write a iterator on the criteria_list list and pass the value of the list in the generate_response function\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "import os, json, ast\n",
        "import openai\n",
        "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
        "from google.colab import drive\n",
        "# Set the display width to control the output width\n",
        "# pd.set_option('display.width', 500)\n",
        "\n",
        "from tenacity import retry, wait_random_exponential, stop_after_attempt"
      ],
      "metadata": {
        "id": "-Xj78zXrJ_Uz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criteria_list ={\n",
        "    \"Scalability and Performance\": [\n",
        "        \"Concurrent user capacity (10,000+, 10% annual growth)\",\n",
        "        \"Data storage and growth management (15% annual increase)\",\n",
        "        \"API throughput and optimization\",\n",
        "        \"Caching strategies and CDN\",\n",
        "        \"Load balancing and failover\",\n",
        "        \"Performance monitoring and alerting\",\n",
        "        \"Database optimization and indexing\",\n",
        "        \"Horizontal vs. vertical scaling strategies\",\n",
        "        \"Capacity planning for peak usage\"\n",
        "    ],\n",
        "    \"Security and Compliance\": [\n",
        "        \"Data encryption (at rest and in transit)\",\n",
        "        \"Access control (roles, sharing, permissions)\",\n",
        "        \"Multi-factor authentication (MFA)\",\n",
        "        \"Compliance (GDPR, CCPA, GLBA, HIPAA, SOX)\",\n",
        "        \"Vulnerability management and penetration testing\",\n",
        "        \"Security auditing and logging\",\n",
        "        \"Data masking and anonymization\",\n",
        "        \"Security certifications and attestations\",\n",
        "        \"Incident response plan\"\n",
        "    ],\n",
        "    \"User Experience and Adoption\": [\n",
        "        \"Intuitive navigation and UI\",\n",
        "        \"Mobile responsiveness and accessibility (WCAG 2.1)\",\n",
        "        \"Personalization (dynamic content, AI recommendations)\",\n",
        "        \"User onboarding and training\",\n",
        "        \"Feedback mechanisms and surveys\",\n",
        "        \"Gamification and community features\",\n",
        "        \"Multi-language support\",\n",
        "        \"User experience testing and optimization\",\n",
        "        \"Accessibility testing with assistive technologies\"\n",
        "    ],\n",
        "    \"Integration and Ecosystem\": [\n",
        "        \"Integration with existing systems (ERP, CRM, core banking)\",\n",
        "        \"API-led connectivity (REST/SOAP)\",\n",
        "        \"Data synchronization and transformation\",\n",
        "        \"AppExchange ecosystem\",\n",
        "        \"Identity provider integration (SSO)\",\n",
        "        \"Data mapping and migration\",\n",
        "        \"Managing technical debt\",\n",
        "        \"Integration architecture and design patterns\",\n",
        "        \"API governance and security\"\n",
        "    ],\n",
        "    \"Administration and Governance\": [\n",
        "        \"User lifecycle management\",\n",
        "        \"Permission set and profile management\",\n",
        "        \"Content moderation and version control\",\n",
        "        \"Audit trail management\",\n",
        "        \"Change management\",\n",
        "        \"Data governance\",\n",
        "        \"Environment management\",\n",
        "        \"Metadata management\",\n",
        "        \"Deployment automation\"\n",
        "    ],\n",
        "    \"Support and Training\": [\n",
        "        \"Support channels (Salesforce, managed services)\",\n",
        "        \"Training resources and documentation\",\n",
        "        \"In-app guidance\",\n",
        "        \"Community knowledge bases\",\n",
        "        \"SLAs\",\n",
        "        \"Knowledge transfer\",\n",
        "        \"Ongoing training\",\n",
        "        \"Training for administrators and developers\",\n",
        "        \"Certification programs\"\n",
        "    ],\n",
        "    \"Disaster Recovery and Uptime\": [\n",
        "        \"Disaster recovery plan\",\n",
        "        \"Data backup and restoration\",\n",
        "        \"Uptime SLAs\",\n",
        "        \"Redundancy\",\n",
        "        \"Business continuity\",\n",
        "        \"DR drills\",\n",
        "        \"Monitoring and alerting\",\n",
        "        \"Recovery Time Objective (RTO) and Recovery Point Objective (RPO)\",\n",
        "        \"Failover testing\"\n",
        "    ],\n",
        "    \"Customization and Flexibility\": [\n",
        "        \"Lightning Web Components and Apex\",\n",
        "        \"Declarative customization\",\n",
        "        \"AppExchange integration\",\n",
        "        \"Branding and theming\",\n",
        "        \"API extensibility\",\n",
        "        \"Managing custom code\",\n",
        "        \"Scalability of customizations\",\n",
        "        \"Customization governance\",\n",
        "        \"Code review and testing processes\"\n",
        "    ],\n",
        "    \"Cost Optimization\": [\n",
        "        \"Licensing model\",\n",
        "        \"Resource utilization\",\n",
        "        \"TCO analysis\",\n",
        "        \"Value engineering\",\n",
        "        \"Cloud infrastructure costs\",\n",
        "        \"Maintenance costs\",\n",
        "        \"ROI analysis\",\n",
        "        \"Optimizing storage and compute resources\",\n",
        "        \"Negotiating contracts with Salesforce\"\n",
        "    ],\n",
        "    \"AI, LLM, and LCM Integration\": [\n",
        "        \"Salesforce Einstein\",\n",
        "        \"LLM use cases (chatbots, content)\",\n",
        "        \"LCM integration\",\n",
        "        \"Data security and privacy for AI/ML\",\n",
        "        \"Ethical implications of AI\",\n",
        "        \"Future AI/ML roadmap\",\n",
        "        \"AI-driven personalization\",\n",
        "        \"Explainable AI and model interpretability\",\n",
        "        \"AI model monitoring and retraining\"\n",
        "    ],\n",
        "    \"Regulatory and Political Landscape (US)\": [\n",
        "        \"Data privacy regulations\",\n",
        "        \"Financial industry regulations\",\n",
        "        \"Political climate\",\n",
        "        \"Cybersecurity regulations\",\n",
        "        \"Data residency\",\n",
        "        \"Legal and compliance reviews\",\n",
        "        \"Monitoring regulatory changes\",\n",
        "        \"Impact of international regulations\",\n",
        "        \"Lobbying and advocacy efforts\"\n",
        "    ],\n",
        "    \"Salesforce Roadmap and Future Plans\": [\n",
        "        \"Product roadmap analysis\",\n",
        "        \"Future features\",\n",
        "        \"Alignment with institution's strategy\",\n",
        "        \"Upgrades and migrations\",\n",
        "        \"Strategic partnerships\",\n",
        "        \"Innovation assessment\",\n",
        "        \"Emerging technologies\",\n",
        "        \"Beta programs and early access features\",\n",
        "        \"Influence of industry trends on Salesforce roadmap\"\n",
        "    ],\n",
        "    \"Resource Reskilling\": [\n",
        "        \"Identifying skill gaps\",\n",
        "        \"Training programs for Salesforce development, administration, and architecture\",\n",
        "        \"Certification programs\",\n",
        "        \"Mentorship programs\",\n",
        "        \"Knowledge transfer from legacy system experts\",\n",
        "        \"Change management strategies for user adoption\",\n",
        "        \"Dedicated budget for training and development\",\n",
        "        \"Cross-training existing resources\",\n",
        "        \"Hiring new talent with Salesforce expertise\"\n",
        "    ],\n",
        "    \"Data Migration and Management\": [\n",
        "        \"Data extraction from legacy systems (Java/Angular/Oracle)\",\n",
        "        \"Data cleansing and transformation\",\n",
        "        \"Data loading into Experience Cloud\",\n",
        "        \"Data validation and reconciliation\",\n",
        "        \"Data governance and quality\",\n",
        "        \"Data archiving and retention policies\",\n",
        "        \"Data security during migration\",\n",
        "        \"Data mapping and schema design\",\n",
        "        \"Performance testing of data migration\",\n",
        "        \"Data migration tools and strategies\"\n",
        "    ],\n",
        "    \"Change Management and User Adoption\": [\n",
        "        \"Communication plan for stakeholders\",\n",
        "        \"User training and enablement programs\",\n",
        "        \"Change impact assessment\",\n",
        "        \"User acceptance testing (UAT)\",\n",
        "        \"Feedback mechanisms and surveys\",\n",
        "        \"Support for early adopters\",\n",
        "        \"Post-implementation review and optimization\",\n",
        "        \"Addressing user resistance to change\",\n",
        "        \"Incentive programs for adoption\",\n",
        "        \"User feedback analysis and action planning\"\n",
        "    ],\n",
        "    \"Vendor Management and Relationship\": [\n",
        "        \"Salesforce contract negotiation\",\n",
        "        \"Service Level Agreements (SLAs)\",\n",
        "        \"Escalation procedures\",\n",
        "        \"Communication channels\",\n",
        "        \"Performance reviews\",\n",
        "        \"Relationship management\",\n",
        "        \"Dependency on Salesforce and vendor lock-in mitigation\",\n",
        "        \"Data ownership and access rights\",\n",
        "        \"Exit strategy\",\n",
        "        \"Regular vendor meetings and communication\"\n",
        "    ],\n",
        "    \"Project Management and Implementation\": [\n",
        "        \"Project scope definition\",\n",
        "        \"Timeline and milestones\",\n",
        "        \"Resource allocation\",\n",
        "        \"Risk management\",\n",
        "        \"Budget management\",\n",
        "        \"Project governance\",\n",
        "        \"Agile or Waterfall methodologies\",\n",
        "        \"Regular project status reporting\",\n",
        "        \"Quality assurance processes\",\n",
        "        \"Project tracking and issue resolution\"\n",
        "    ],\n",
        "    \"Innovation and Future-Proofing\": [\n",
        "        \"Staying current with Salesforce releases and updates\",\n",
        "        \"Exploring emerging technologies (e.g., blockchain, Web3)\",\n",
        "        \"Evaluating potential integrations with other platforms\",\n",
        "        \"Developing a roadmap for future enhancements\",\n",
        "        \"Participating in Salesforce community and events\",\n",
        "        \"Benchmarking against industry best practices\",\n",
        "        \"Building a culture of innovation within the team\",\n",
        "        \"Experimenting with new features in sandbox environments\",\n",
        "        \"Monitoring industry trends and adapting the platform accordingly\",\n",
        "        \"Continuous improvement and optimization of the platform\"\n",
        "    ]\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "5ZtycfThtJQj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the necessary library for mounting Google Drive\n",
        "\n",
        "# Mounting Google Drive to the Colab environment\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "# Read the API key from the text file and strip any leading or trailing whitespace\n",
        "with open(\"/content/drive/My Drive/Gen_AI/OPENAI_API_Key.txt\", \"r\") as f:\n",
        "    api_key = f.read().strip()\n",
        "\n",
        "# Set the API key for OpenAI\n",
        "openai.api_key = api_key\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygCBmJOatD41",
        "outputId": "3a3a8fb8-f771-4052-9c8e-6bb9f5a0ee18",
        "collapsed": true
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Retry up to 6 times with exponential backoff, starting at 1 second and maxing out at 20 seconds delay\n",
        "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
        "def generate_ai_response(criterion,subcriterion):\n",
        "    \"\"\"\n",
        "    Generate a response using gpt-4o-mini ChatCompletion based on the user query and retrieved information.\n",
        "    \"\"\"\n",
        "    system_content=\"You are a helpful AI assistant in the Financial Technology consulting domain, specialized in providing accurate answers.\"\n",
        "\n",
        "    user_content= f\"\"\"\n",
        "                  Imagine a panel discussion featuring four industry experts, each bringing specialized insights into the migration of a US-based financial institution’s legacy system to Salesforce Experience Cloud. The institution currently operates on a custom-built system using Java, Angular, FTL, Oracle, and custom APIs. The objective is to modernize operations, enhance customer and partner engagement, ensure compliance, and maximize Return on Investment (ROI).\n",
        "\n",
        "                  Expert Panelists:\n",
        "                  Salesforce Solution Architect – Specializes in migrating legacy systems to Salesforce while ensuring data integrity, security, and scalability.\n",
        "                  Financial Industry Consultant – Provides expertise in regulatory compliance (GDPR, CCPA, GLBA, SOX), risk mitigation, and security requirements for US financial institutions.\n",
        "                  Legacy System Migration Specialist – Focuses on transitioning from Java, Angular, Oracle-based systems to Salesforce Experience Cloud, addressing data migration, technical debt, and operational continuity.\n",
        "                  Customer Experience (CX) Strategist – Ensures the new solution delivers a seamless, user-friendly experience, improves engagement, and drives business value.\n",
        "                  Discussion Focus:\n",
        "                  Main Topic: {criterion}\n",
        "                  Sub-Topic: {subcriterion}\n",
        "\n",
        "                  The discussion evaluates the adoption of Salesforce Experience Cloud as an alternative to the current home-grown solution while addressing key challenges such as minimizing disruption, ensuring compliance, enhancing digital experiences, and optimizing ROI.\n",
        "\n",
        "                  Each expert provides a unique perspective:\n",
        "\n",
        "                  Solution Architect – Technical challenges, API integrations, scalability, and security.\n",
        "                  Industry Consultant – Compliance, security, and risk management.\n",
        "                  Migration Specialist – Transition complexities, downtime mitigation, and resource upskilling.\n",
        "                  CX Strategist – User experience, personalization, and engagement strategies.\n",
        "                  Deliverables:\n",
        "                  The panel will collaboratively define evaluation criteria, subcriteria, and parameters, assigning an importance scale (1-5) to assess their impact.\n",
        "\n",
        "                  Structured Output:\n",
        "                  A Markdown-style table with four columns, strictly in this order:\n",
        "                  Evaluation Criterion – The main topic ({criterion}).\n",
        "                  Importance Scale – A score (1-5) indicating {criterion}’s significance.\n",
        "                  Evaluation Subcriterion – The sub-topic ({subcriterion}).\n",
        "                  Parameters of the Subcriterion – Specific parameters used to evaluate {subcriterion}.\n",
        "\n",
        "                  Each subcriterion must have top, at least 7 parameters and maximum 10 parameters.These parameter must be comma(,) saperate values for evaluation.\n",
        "                  In Table's row  must not repeat Criterion and subsriterion.\n",
        "                  The discussion will cover key challenges, proposed solutions, and success measurement metrics to ensure an informed transition to Salesforce Experience Cloud.\n",
        "                  \"\"\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_content },\n",
        "        {\"role\": \"user\", \"content\": user_content },\n",
        "    ]\n",
        "\n",
        "    response = openai.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=messages\n",
        "    )\n",
        "    # Accessing content from the response object using .choices attribute\n",
        "    content = response.choices[0].message.content\n",
        "    print(content)\n",
        "\n",
        "    return content\n"
      ],
      "metadata": {
        "id": "wzxfwax8FSHZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import re\n",
        "\n",
        "# Step 1: Extract Table Data from Markdown\n",
        "def extract_table(content):\n",
        "    lines = content.split(\"\\n\")\n",
        "    table_lines = [line for line in lines if \"|\" in line]  # Extract only table lines\n",
        "    if len(table_lines) < 3:\n",
        "        return None  # No valid table found\n",
        "\n",
        "    headers = [h.strip() for h in table_lines[0].split(\"|\")[1:-1]]  # Extract headers\n",
        "    data = []\n",
        "    for line in table_lines[2:]:  # Skip the header and separator line\n",
        "        values = [v.strip() for v in line.split(\"|\")[1:-1]]\n",
        "        if values:\n",
        "            data.append(values)\n",
        "\n",
        "    return headers, data\n",
        "\n",
        "# Step 2: Extract Discussion Summary and ROI Framework\n",
        "def extract_section(content, section_title):\n",
        "    match = re.search(f\"### {section_title}(.*?)(###|$)\", content, re.DOTALL)\n",
        "    return match.group(1).strip() if match else \"\"\n",
        "\n",
        "\n",
        "# def save_to_excel(headers, data, discussion, roi, filename):\n",
        "def save_to_excel(headers, data, filename):\n",
        "\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    filename = f\"{filename}_{timestamp}.xlsx\"\n",
        "    filepath = f\"/content/drive/My Drive/Gen_AI/{filename}\"\n",
        "\n",
        "    # Concatenate all DataFrames in the list\n",
        "    all_data_df = pd.concat(data, ignore_index=True)\n",
        "\n",
        "    with pd.ExcelWriter(filepath, engine=\"openpyxl\") as writer:\n",
        "        # Save Table Data\n",
        "        if headers and not all_data_df.empty:  # Check if 'all_data_df' DataFrame is not empty\n",
        "            all_data_df.to_excel(writer, sheet_name=\"Evaluation Criteria\", index=False) # Write DataFrame directly\n",
        "\n",
        "\n",
        "    print(f\"✅ Report saved successfully as: {filepath}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "wXV4uNAtRdYZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To generate the excels\n",
        "\n",
        "import pandas as pd\n",
        "from numpy import NaN\n",
        "\n",
        "df_all = []\n",
        "\n",
        "for criterion, subcriteria in criteria_list.items():\n",
        "    df_criterion=[]\n",
        "    for item in subcriteria:\n",
        "        content = generate_ai_response(criterion, item)\n",
        "        headers, data = extract_table(content)\n",
        "        # Convert 'data' to a DataFrame to use iterrows\n",
        "        df_data = pd.DataFrame(data, columns=headers)  # Create a DataFrame from data and headers\n",
        "        df_all.append(df_data)\n",
        "        df_criterion.append(df_data)\n",
        "        print(\"df_data --->\\n\",df_data)\n",
        "    # Generate a unique sheet name based on the criterion and loop index\n",
        "    sheet_name = f\"{criterion}-Evaluation Criteria\"\n",
        "    save_to_excel(headers, df_criterion, sheet_name) # Pass the sheet name to the function\n",
        "\n",
        "sheet_name = f\"Evaluation Criteria - {criterion}\"\n",
        "save_to_excel(headers, df_all, \"All_criterion\") # Pass the sheet name to the function\n",
        "\n"
      ],
      "metadata": {
        "id": "aAxh3w_ZMXPG",
        "collapsed": true
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def expand_rows(input_file, output_file):\n",
        "    # Load the Excel file\n",
        "    df = pd.read_excel(input_file)\n",
        "\n",
        "    # Ensure the necessary column exists\n",
        "    column_to_split = \"Parameters of the Subcriterion\"\n",
        "    if column_to_split not in df.columns:\n",
        "        raise ValueError(f\"Column '{column_to_split}' not found in the input file.\")\n",
        "\n",
        "    # Expand rows\n",
        "    df_expanded = df.assign(**{column_to_split: df[column_to_split].str.split(',')})\n",
        "    df_expanded = df_expanded.explode(column_to_split)\n",
        "\n",
        "    # Trim spaces from the split values\n",
        "    df_expanded[column_to_split] = df_expanded[column_to_split].str.strip()\n",
        "\n",
        "    # Save to new Excel file\n",
        "    df_expanded.to_excel(output_file, index=False)\n",
        "    print(f\"Expanded file saved as: {output_file}\")\n"
      ],
      "metadata": {
        "id": "i3RG_xxlfAId"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "\n",
        "def get_matching_files(folder_path, search_value):\n",
        "    matching_files = []\n",
        "    # List all files in the folder\n",
        "    for file_name in os.listdir(folder_path):\n",
        "        if search_value in file_name:\n",
        "            matching_files.append(file_name)\n",
        "    return matching_files\n",
        "\n",
        "def expand_rows(input_file, output_file, sheet_name):\n",
        "    # Load the Excel file\n",
        "    df = pd.read_excel(input_file)\n",
        "    # Ensure the necessary column exists\n",
        "    column_to_split = \"Parameters of the Subcriterion\"\n",
        "    if column_to_split not in df.columns:\n",
        "        raise ValueError(f\"Column '{column_to_split}' not found in the input file.\")\n",
        "    # Expand rows\n",
        "    df_expanded = df.assign(**{column_to_split: df[column_to_split].str.split(',')})\n",
        "    df_expanded = df_expanded.explode(column_to_split)\n",
        "    # Trim spaces from the split values\n",
        "    df_expanded[column_to_split] = df_expanded[column_to_split].str.strip()\n",
        "    # Save to new Excel file with specified sheet name\n",
        "\n",
        "    # **Instead of appending, write all dataframes to a dictionary and save at once**\n",
        "    if not os.path.exists(output_file):\n",
        "        all_dfs = {sheet_name: df_expanded}  # Initialize with the first sheet\n",
        "    else:\n",
        "        all_dfs = pd.read_excel(output_file, sheet_name=None)  # Read all sheets\n",
        "        all_dfs[sheet_name] = df_expanded  # Add the current sheet\n",
        "\n",
        "    # **Write all sheets to the output file**\n",
        "    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
        "        for sheet_name, df in all_dfs.items():\n",
        "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
        "    print(f\"Expanded file saved as: {output_file}, sheet name: {sheet_name}\")\n",
        "\n",
        "def extract_criterion(filename):\n",
        "    # Modified regex to handle \"All_criterion\"\n",
        "    match = re.match(r\"^(.*?)(?:-Evaluation Criteria|_).*\", filename)\n",
        "    if match:\n",
        "      return match.group(1)\n",
        "    else:\n",
        "      return None"
      ],
      "metadata": {
        "id": "CMsFgbF6iKQ3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = \"/content/drive/My Drive/Gen_AI/\"  # Replace with your folder path\n",
        "search_value = \"20250222\"\n",
        "matching_files = get_matching_files(folder_path, search_value)\n",
        "\n",
        "for file_name in matching_files:\n",
        "  input_file = f\"/content/drive/My Drive/Gen_AI/{file_name}\"  # Replace with your actual file name\n",
        "  sheet_name = extract_criterion(file_name)\n",
        "  output_file = f\"/content/drive/My Drive/Gen_AI/Out/All_In_One.xlsx\"  # Output file name\n",
        "  print(\"input_file-->\",input_file)\n",
        "  print(\"output_file-->\",output_file)\n",
        "  print(\"sheet_name-->\",sheet_name)\n",
        "  expand_rows(input_file, output_file, sheet_name)"
      ],
      "metadata": {
        "id": "52x5p-K0lkq0",
        "collapsed": true
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}